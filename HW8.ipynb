{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Задание\n",
        "Решить задачу перевода с помощью механизма внимания\n",
        "\n",
        "* Возьмите англо-русскую пару фраз (https://www.manythings.org/anki/)\n",
        "*  Обучите на них seq2seq with attention\n",
        "  - На основе скалярного произведения\n",
        "  - На основе MLP\n",
        "Оцените качество"
      ],
      "metadata": {
        "id": "ZoeTKeKL6Ebr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFfkS6pRjHOR"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.manythings.org/anki/rus-eng.zip\n",
        "!unzip rus-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHtAeHLLjJYd",
        "outputId": "ade19c0e-2a51-4cf0-8b70-afd0133c2869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-23 17:00:53--  https://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15011848 (14M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip.1’\n",
            "\n",
            "rus-eng.zip.1       100%[===================>]  14.32M  18.1MB/s    in 0.8s    \n",
            "\n",
            "2023-01-23 17:00:54 (18.1 MB/s) - ‘rus-eng.zip.1’ saved [15011848/15011848]\n",
            "\n",
            "Archive:  rus-eng.zip\n",
            "replace rus.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail rus.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0yfRzsUjKyC",
        "outputId": "6665dd61-ee08-4703-ded3-4ff602bfe08c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We need to uphold laws against discrimination — in hiring, and in housing, and in education, and in the criminal justice system. That is what our Constitution and our highest ideals require.\tНам нужно отстаивать законы против дискриминации при найме на работу, в жилищной сфере, в сфере образования и правоохранительной системе. Этого требуют наша Конституция и высшие идеалы.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762728 (BHO) & #6390439 (odexed)\n",
            "I've heard that you should never date anyone who is less than half your age plus seven. Tom is now 30 years old and Mary is 17. How many years will Tom need to wait until he can start dating Mary?\tЯ слышал, что никогда не следует встречаться с кем-то вдвое младше вас плюс семь лет. Тому 30 лет, a Мэри 17. Сколько лет Тому нужно ждать до тех пор, пока он сможет начать встречаться с Мэри?\tCC-BY 2.0 (France) Attribution: tatoeba.org #10068197 (CK) & #10644473 (notenoughsun)\n",
            "I do have one final ask of you as your president, the same thing I asked when you took a chance on me eight years ago. I'm asking you to believe, not in my ability to bring about change but in yours.\tУ меня же, как у вашего президента, есть к вам последняя просьба. Та же самая, что и восемь лет назад, когда вы оказали мне своё доверие. Я прошу вас верить, но не в мои способности добиться перемен, а в ваши.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762723 (BHO) & #6390123 (odexed)\n",
            "In today's world, we have to equip all our kids with an education that prepares them for success, regardless of what they look like, or how much their parents make, or the zip code that they live in.\tВ современном мире перед нами стоит задача дать всем нашим детям такое образование, которое настроит их на успех вне зависимости от того, как они выглядят, сколько зарабатывают их родители или какой у них почтовый индекс.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924477 (BHO) & #5968115 (odexed)\n",
            "Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\tСмерть - это зачастую то, разговоры или даже мысли о чем приводят в уныние, но я осознал, что готовность умереть наделяет силой, как ничто другое. Мысль о смерти вносит ясность в твою жизнь.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #3231553 (kukla)\n",
            "At a moment when our economy is growing, our businesses are creating jobs at the fastest pace since the 1990s, and wages are starting to rise again, we have to make some choices about the kind of country we want to be.\tВ тот момент, когда наша экономика растёт, наши предприятия создают рабочие места наибольшими темпами, начиная с 90-х годов, а зарплаты снова начинают расти, мы должны принять ряд решений относительно того, какой страной мы хотим быть.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924474 (BHO) & #4509418 (odexed)\n",
            "When I was younger, I hated going to weddings. My grandmothers and aunts would huddle around me, poke me in the side, and giggle \"You're next! You're next!\" They only stopped this nonsense when I began to do the same thing at funerals.\tКогда я была помоложе, я ненавидела ходить на свадьбы. Мои бабушки и тётки толпились вокруг, тыкали меня в бок и говорили, посмеиваясь: «Ты следующая! Ты следующая!». Они перестали нести этот вздор только тогда, когда я начала делать то же самое на похоронах.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2776770 (AlanF_US) & #4311406 (odexed)\n",
            "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\tПоскольку сайтов, посвящённых какой-либо теме, как правило, несколько, я обычно просто нажимаю на кнопку \"назад\", если попадаю на страницу со всплывающей рекламой. Я просто перехожу на следующую страницу, найденную гуглом, и надеюсь найти что-то менее раздражающее.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #6383010 (odexed)\n",
            "If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\tЕсли кто-то незнакомый говорит, что вы говорите как носитель языка, это значит, что он, вероятно, заметил что-то в вашей речи, что дало ему понять, что вы не носитель. Другими словами, вы не говорите как носитель.\tCC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #10644468 (notenoughsun)\n",
            "Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\tНесомненно, для каждого мужчины в этом мире где-то есть подходящая женщина, которая может стать ему женой, обратное верно и для женщин. Но если учесть, что у человека может быть максимум несколько сотен знакомых, из которых лишь дюжина, а то и меньше, тех, кого он знает близко, а из этой дюжины у него один или от силы два друга, то можно легко увидеть, что с учётом миллионов живущих на Земле людей, ни один подходящий мужчина, возможно, ещё не встретил подходящую женщину.\tCC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7730831 (odexed)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "MtxSF1HljMcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+а-яА-Я\", r\" \", s)\n",
        "    return s"
      ],
      "metadata": {
        "id": "XMBj-QRDjQSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('rus.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "    \n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')[:-1]] for l in lines]\n",
        "    #for p in pairs:\n",
        "    #    p.pop()\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "\n",
        "    else:\n",
        "\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "    \n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "tljl5hVfjR7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s\",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "   \n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "yOLjuxPMjTXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'rus', True)\n",
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vi_9rdzjU6a",
        "outputId": "a3e31217-ee1a-447c-f115-4ba9d3daae2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 451436 sentence pairs\n",
            "Trimmed to 4196 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 3874\n",
            "eng 2060\n",
            "['я не студент .', 'i am not a student .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Encoder\n",
        "-----------"
      ],
      "metadata": {
        "id": "b-0Pt5oZjZUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "7Cn_FUFKjdTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Decoder\n",
        "-----------\n"
      ],
      "metadata": {
        "id": "vt7mU-JvjeUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "qg__g07Tjf5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "class AttnDecoderRNN_MLP(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN_MLP, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)       \n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "        self.Wk = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.Wq = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        wk = self.Wk(hidden.squeeze(0))\n",
        "        wq = self.Wq(encoder_outputs)\n",
        "\n",
        "        attn_weights = torch.tanh(wk + wq) \n",
        "        attn_weights = torch.bmm(embedded, attn_weights.T.unsqueeze(0))       \n",
        "        attn_weights = F.softmax(attn_weights.squeeze(0), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "        \n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "class AttnDecoderRNN_Scalar(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN_Scalar, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax((embedded[0] @ encoder_outputs.T) / self.max_length**0.5, dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))  \n",
        "        \n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)        \n",
        "        output = self.attn_combine(output).unsqueeze(0)        \n",
        "        output = F.relu(output)        \n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "u_dIirzeJ4UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "wyThYIDtjimi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "metadata": {
        "id": "MDP9ut87jkCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "TJyKxGLYjl4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "Oa0AOmoejnRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervalsA\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "fjPg_UZAjowK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "metadata": {
        "id": "FtnGAKyfjqRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "SdsN7Hyxjr0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 50000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUFXA6AWjtKC",
        "outputId": "cb0870ec-45a1-4d34-d3ce-9de53d3a38e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3m 48s (- 34m 12s) (5000 10%) 3.0679\n",
            "7m 34s (- 30m 18s) (10000 20%) 2.4140\n",
            "11m 41s (- 27m 17s) (15000 30%) 1.9224\n",
            "16m 2s (- 24m 4s) (20000 40%) 1.5317\n",
            "20m 14s (- 20m 14s) (25000 50%) 1.1944\n",
            "24m 9s (- 16m 6s) (30000 60%) 0.9123\n",
            "28m 9s (- 12m 4s) (35000 70%) 0.6720\n",
            "32m 1s (- 8m 0s) (40000 80%) 0.5141\n",
            "35m 54s (- 3m 59s) (45000 90%) 0.3977\n",
            "39m 51s (- 0m 0s) (50000 100%) 0.2913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1, 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtlMUOYNjuZq",
        "outputId": "7c4de39b-4e8a-4e79-bdc7-9d5f78093eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> я тот, кто я есть .\n",
            "= i am who i am .\n",
            "< i am who i am . <EOS>\n",
            "\n",
            "> мы не подготовлены .\n",
            "= we aren't prepared .\n",
            "< we aren't bored . <EOS>\n",
            "\n",
            "> мы сеичас ничего не делаем .\n",
            "= we aren't doing anything right now .\n",
            "< we aren't doing anything right now . <EOS>\n",
            "\n",
            "> они заняты .\n",
            "= they are busy .\n",
            "< they are busy . <EOS>\n",
            "\n",
            "> у меня все в порядке .\n",
            "= i am okay .\n",
            "< i am well . <EOS>\n",
            "\n",
            "> он мои враг .\n",
            "= he is my enemy .\n",
            "< he is my enemy . <EOS>\n",
            "\n",
            "> он одинок .\n",
            "= he is alone .\n",
            "< he is alone . <EOS>\n",
            "\n",
            "> он выше таких деиствии .\n",
            "= he is above doing such a thing .\n",
            "< he is above doing such a thing . <EOS>\n",
            "\n",
            "> он имеет право на лучшее обращение .\n",
            "= he is entitled to better treatment .\n",
            "< he is able to such on . <EOS>\n",
            "\n",
            "> она путешествует по миру .\n",
            "= she is traveling around the world .\n",
            "< she is traveling around the world . <EOS>\n",
            "\n",
            "> я не женат .\n",
            "= i am not married .\n",
            "< i am not married . <EOS>\n",
            "\n",
            "> я очень сожалею о том, что я сказал .\n",
            "= i am very sorry for what i said .\n",
            "< i am very sorry for what i said . <EOS>\n",
            "\n",
            "> он работает на поприще биологии .\n",
            "= he is working in the field of biology .\n",
            "< he is working in the field of biology . <EOS>\n",
            "\n",
            "> он всего лишь ребенок .\n",
            "= he is just a child .\n",
            "< he is only a child . <EOS>\n",
            "\n",
            "> я на вас рассчитываю .\n",
            "= i am counting on you .\n",
            "< i am counting on you . <EOS>\n",
            "\n",
            "> она моя одноклассница .\n",
            "= she is my classmate .\n",
            "< she is my classmate . <EOS>\n",
            "\n",
            "> еи противна ее работа .\n",
            "= she is disgusted with the job .\n",
            "< she is disgusted with the job . <EOS>\n",
            "\n",
            "> вы мои пленник .\n",
            "= you are my prisoner .\n",
            "< you are my prisoner . <EOS>\n",
            "\n",
            "> она математическии гении .\n",
            "= she is a genius at mathematics .\n",
            "< she is a genius at mathematics . <EOS>\n",
            "\n",
            "> она хорошо плавает .\n",
            "= she swims well .\n",
            "< she swims well . <EOS>\n",
            "\n",
            "> вы преподаватель .\n",
            "= you are a teacher .\n",
            "< you are a teacher . <EOS>\n",
            "\n",
            "> он начинает лысеть .\n",
            "= he is beginning to lose his hair .\n",
            "< he is beginning to lose his hair . <EOS>\n",
            "\n",
            "> он красивыи мужчина .\n",
            "= he is a handsome man .\n",
            "< he is a handsome man . <EOS>\n",
            "\n",
            "> ему трудно дышать .\n",
            "= he is having difficulty breathing .\n",
            "< he is having difficulty breathing . <EOS>\n",
            "\n",
            "> она предложила мне отменить совещание .\n",
            "= she suggested that i cancel the meeting .\n",
            "< she suggested that i cancel the meeting . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder_Scalar = AttnDecoderRNN_Scalar(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder_Scalar, 50000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14Uv-oQNLB0w",
        "outputId": "e4b23b9c-7f24-48f6-88a1-ddeb652543a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3m 43s (- 33m 27s) (5000 10%) 3.0466\n",
            "7m 31s (- 30m 5s) (10000 20%) 2.4672\n",
            "11m 18s (- 26m 23s) (15000 30%) 1.9724\n",
            "15m 7s (- 22m 41s) (20000 40%) 1.5609\n",
            "18m 53s (- 18m 53s) (25000 50%) 1.2534\n",
            "22m 41s (- 15m 7s) (30000 60%) 0.9459\n",
            "26m 30s (- 11m 21s) (35000 70%) 0.7333\n",
            "30m 28s (- 7m 37s) (40000 80%) 0.5642\n",
            "34m 20s (- 3m 48s) (45000 90%) 0.4108\n",
            "38m 18s (- 0m 0s) (50000 100%) 0.3027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder1, attn_decoder_Scalar, 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S20AzE98LCVn",
        "outputId": "4983f5e1-1e8a-4400-fefa-5542960f0bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> вы нас не убедили .\n",
            "= we aren't convinced .\n",
            "< we aren't convinced . <EOS>\n",
            "\n",
            "> его невозможно превзоити .\n",
            "= he is impossible to beat .\n",
            "< he is impossible to beat . <EOS>\n",
            "\n",
            "> мы стоим перед трудным выбором .\n",
            "= we are faced with a difficult choice .\n",
            "< we are faced with a difficult choice . <EOS>\n",
            "\n",
            "> он занят написанием отчетов .\n",
            "= he is busy typing the reports .\n",
            "< he is busy typing the reports . <EOS>\n",
            "\n",
            "> они ужинают .\n",
            "= they are having dinner .\n",
            "< they are having dinner . <EOS>\n",
            "\n",
            "> вы начинающие, но быстро учитесь .\n",
            "= you are beginners, but you learn quickly .\n",
            "< you are beginners, but you learn quickly . <EOS>\n",
            "\n",
            "> они мои сестры .\n",
            "= they are my sisters .\n",
            "< they are my sisters . <EOS>\n",
            "\n",
            "> вы трудоголик .\n",
            "= you are a workaholic .\n",
            "< you are a workaholic . <EOS>\n",
            "\n",
            "> они добры к пожилым людям .\n",
            "= they are kind to old people .\n",
            "< they are kind to old people . <EOS>\n",
            "\n",
            "> я свободен до шести этим вечером .\n",
            "= i am free till 6 o'clock this evening .\n",
            "< i am free free next this evening . <EOS>\n",
            "\n",
            "> она всегда одета в черное .\n",
            "= she is always dressed in black .\n",
            "< she is always dressed in black . <EOS>\n",
            "\n",
            "> он изучает сельское хозяиство .\n",
            "= he is studying agriculture .\n",
            "< he is studying history . <EOS>\n",
            "\n",
            "> вы не лучше меня .\n",
            "= you aren't better than me .\n",
            "< you aren't better than me . <EOS>\n",
            "\n",
            "> он боится плавать .\n",
            "= he is afraid to swim .\n",
            "< he is afraid to swim . <EOS>\n",
            "\n",
            "> я не тупои .\n",
            "= i am not stupid .\n",
            "< i am not stupid . <EOS>\n",
            "\n",
            "> у нее очень хорошее настроение .\n",
            "= she is in a very good mood .\n",
            "< she is in a very good mood . <EOS>\n",
            "\n",
            "> он, вероятно, придет .\n",
            "= he is likely to come .\n",
            "< he is likely to come . <EOS>\n",
            "\n",
            "> он очень искреннии человек .\n",
            "= he is a very sincere person .\n",
            "< he is a very sincere person . <EOS>\n",
            "\n",
            "> она очень популярна среди студентов .\n",
            "= she is very popular among the students .\n",
            "< she is very popular among the boys . <EOS>\n",
            "\n",
            "> ты не идеальна .\n",
            "= you aren't perfect .\n",
            "< you aren't perfect . <EOS>\n",
            "\n",
            "> мы в одном классе .\n",
            "= we are in the same class .\n",
            "< we are both in the same class . <EOS>\n",
            "\n",
            "> ты ошибаешься насчет этого .\n",
            "= you are mistaken about that .\n",
            "< you are mistaken about that . <EOS>\n",
            "\n",
            "> они оба очень умные .\n",
            "= they are both very intelligent .\n",
            "< they are both very intelligent . <EOS>\n",
            "\n",
            "> он по-прежнему занят .\n",
            "= he is as busy as ever .\n",
            "< he is as busy as ever . <EOS>\n",
            "\n",
            "> ты глупее, чем я думал .\n",
            "= you are more stupid than i thought .\n",
            "< you are more stupid than i . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder_MLP = AttnDecoderRNN_MLP(hidden_size, output_lang.n_words, dropout_p=0).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder_MLP, 30000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO3rqmuSLDa-",
        "outputId": "9234f232-06e1-4209-f311-8d7d908b9a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4m 18s (- 21m 31s) (5000 16%) 3.0821\n",
            "8m 47s (- 17m 35s) (10000 33%) 2.4845\n",
            "13m 11s (- 13m 11s) (15000 50%) 2.0521\n",
            "17m 34s (- 8m 47s) (20000 66%) 1.6894\n",
            "21m 59s (- 4m 23s) (25000 83%) 1.4029\n",
            "26m 23s (- 0m 0s) (30000 100%) 1.2065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder1, attn_decoder_MLP, 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZex7h6bLDkZ",
        "outputId": "adeec759-08b9-4b1f-b1c2-674723a44317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> я его друг и останусь им .\n",
            "= i am his friend and will remain so .\n",
            "< i am a his and friend is . friend .\n",
            "\n",
            "> она кричала, что я виноват .\n",
            "= she screamed that i was to blame .\n",
            "< she is the that to . <EOS>\n",
            "\n",
            "> завтра я не на службе .\n",
            "= i am off duty tomorrow .\n",
            "< i am not on now . <EOS>\n",
            "\n",
            "> она ее подруга .\n",
            "= she is her friend .\n",
            "< she is her friend . <EOS>\n",
            "\n",
            "> он на три года младше меня .\n",
            "= he is younger than me by three years .\n",
            "< he is younger than me by three years . <EOS>\n",
            "\n",
            "> я слишком низкии .\n",
            "= i am too short .\n",
            "< i am too . . <EOS>\n",
            "\n",
            "> он жестокии человек .\n",
            "= he is a cruel person .\n",
            "< he is a man man . <EOS>\n",
            "\n",
            "> мы еще не готовы .\n",
            "= we aren't yet ready .\n",
            "< we aren't ready . <EOS>\n",
            "\n",
            "> она мертва .\n",
            "= she is dead .\n",
            "< she is crazy . <EOS>\n",
            "\n",
            "> он свободно владеет фарси .\n",
            "= he is proficient in farsi .\n",
            "< he is a by in by profession . <EOS>\n",
            "\n",
            "> они добры к пожилым людям .\n",
            "= they are kind to old people .\n",
            "< they are kind to old old . <EOS>\n",
            "\n",
            "> она сказала, что ее зовут мэри .\n",
            "= she said her name was mary .\n",
            "< she said her was ill . <EOS>\n",
            "\n",
            "> она может петь очень хорошо .\n",
            "= she is able to sing very well .\n",
            "< she is very pretty at all the . . <EOS>\n",
            "\n",
            "> я старая .\n",
            "= i am old .\n",
            "< i am old . <EOS>\n",
            "\n",
            "> она способна на все .\n",
            "= she is capable of anything .\n",
            "< she is all on the . <EOS>\n",
            "\n",
            "> мы не идем .\n",
            "= we aren't going .\n",
            "< we aren't going . <EOS>\n",
            "\n",
            "> ее сеичас тут нет .\n",
            "= she is out now .\n",
            "< she is here now . <EOS>\n",
            "\n",
            "> я очень грустныи человек .\n",
            "= i am a very sad person .\n",
            "< i am a very person person person . <EOS>\n",
            "\n",
            "> она ужасно готовит .\n",
            "= she is terrible at cooking .\n",
            "< she is at a cooking . <EOS>\n",
            "\n",
            "> с ним довольно трудно поладить .\n",
            "= he is rather hard to get along with .\n",
            "< he is hard with with with . <EOS>\n",
            "\n",
            "> они очень популярны среди парнеи .\n",
            "= they are very popular among boys .\n",
            "< they are very popular among boys . <EOS>\n",
            "\n",
            "> я лучше, чем ты .\n",
            "= i am better than you .\n",
            "< i am better than you . <EOS>\n",
            "\n",
            "> он хорошо играет в футбол .\n",
            "= he is good at soccer .\n",
            "< he is good at playing tennis . <EOS>\n",
            "\n",
            "> они страдают от голода .\n",
            "= they are suffering from hunger .\n",
            "< they are all alike from my . <EOS>\n",
            "\n",
            "> он высокии и сильныи .\n",
            "= he is tall and strong .\n",
            "< he is a tall and . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HfqwZOeQLyNO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}