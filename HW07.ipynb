{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Задание\n",
        "* Возьмите англо-русскую пару фраз (https://www.manythings.org/anki/)\n",
        "* Обучите на них seq2seq по аналогии с занятием. Оцените полученное качество\n",
        "* Попробуйте добавить +1 рекуррентный слой в encoder и decoder\n",
        "* Попробуйте заменить GRU ячейки на lstm-ячейки"
      ],
      "metadata": {
        "id": "ZoeTKeKL6Ebr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFfkS6pRjHOR"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.manythings.org/anki/rus-eng.zip\n",
        "!unzip rus-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHtAeHLLjJYd",
        "outputId": "8dfa2a24-725f-4df1-8a5c-48ddd80e8a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-21 13:45:10--  https://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15011848 (14M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip.1’\n",
            "\n",
            "rus-eng.zip.1       100%[===================>]  14.32M  21.1MB/s    in 0.7s    \n",
            "\n",
            "2023-01-21 13:45:11 (21.1 MB/s) - ‘rus-eng.zip.1’ saved [15011848/15011848]\n",
            "\n",
            "Archive:  rus-eng.zip\n",
            "replace rus.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: _about.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail rus.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0yfRzsUjKyC",
        "outputId": "311e19b5-f354-47f2-f05a-ceb733476e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We need to uphold laws against discrimination — in hiring, and in housing, and in education, and in the criminal justice system. That is what our Constitution and our highest ideals require.\tНам нужно отстаивать законы против дискриминации при найме на работу, в жилищной сфере, в сфере образования и правоохранительной системе. Этого требуют наша Конституция и высшие идеалы.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762728 (BHO) & #6390439 (odexed)\n",
            "I've heard that you should never date anyone who is less than half your age plus seven. Tom is now 30 years old and Mary is 17. How many years will Tom need to wait until he can start dating Mary?\tЯ слышал, что никогда не следует встречаться с кем-то вдвое младше вас плюс семь лет. Тому 30 лет, a Мэри 17. Сколько лет Тому нужно ждать до тех пор, пока он сможет начать встречаться с Мэри?\tCC-BY 2.0 (France) Attribution: tatoeba.org #10068197 (CK) & #10644473 (notenoughsun)\n",
            "I do have one final ask of you as your president, the same thing I asked when you took a chance on me eight years ago. I'm asking you to believe, not in my ability to bring about change but in yours.\tУ меня же, как у вашего президента, есть к вам последняя просьба. Та же самая, что и восемь лет назад, когда вы оказали мне своё доверие. Я прошу вас верить, но не в мои способности добиться перемен, а в ваши.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762723 (BHO) & #6390123 (odexed)\n",
            "In today's world, we have to equip all our kids with an education that prepares them for success, regardless of what they look like, or how much their parents make, or the zip code that they live in.\tВ современном мире перед нами стоит задача дать всем нашим детям такое образование, которое настроит их на успех вне зависимости от того, как они выглядят, сколько зарабатывают их родители или какой у них почтовый индекс.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924477 (BHO) & #5968115 (odexed)\n",
            "Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\tСмерть - это зачастую то, разговоры или даже мысли о чем приводят в уныние, но я осознал, что готовность умереть наделяет силой, как ничто другое. Мысль о смерти вносит ясность в твою жизнь.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #3231553 (kukla)\n",
            "At a moment when our economy is growing, our businesses are creating jobs at the fastest pace since the 1990s, and wages are starting to rise again, we have to make some choices about the kind of country we want to be.\tВ тот момент, когда наша экономика растёт, наши предприятия создают рабочие места наибольшими темпами, начиная с 90-х годов, а зарплаты снова начинают расти, мы должны принять ряд решений относительно того, какой страной мы хотим быть.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924474 (BHO) & #4509418 (odexed)\n",
            "When I was younger, I hated going to weddings. My grandmothers and aunts would huddle around me, poke me in the side, and giggle \"You're next! You're next!\" They only stopped this nonsense when I began to do the same thing at funerals.\tКогда я была помоложе, я ненавидела ходить на свадьбы. Мои бабушки и тётки толпились вокруг, тыкали меня в бок и говорили, посмеиваясь: «Ты следующая! Ты следующая!». Они перестали нести этот вздор только тогда, когда я начала делать то же самое на похоронах.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2776770 (AlanF_US) & #4311406 (odexed)\n",
            "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\tПоскольку сайтов, посвящённых какой-либо теме, как правило, несколько, я обычно просто нажимаю на кнопку \"назад\", если попадаю на страницу со всплывающей рекламой. Я просто перехожу на следующую страницу, найденную гуглом, и надеюсь найти что-то менее раздражающее.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #6383010 (odexed)\n",
            "If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\tЕсли кто-то незнакомый говорит, что вы говорите как носитель языка, это значит, что он, вероятно, заметил что-то в вашей речи, что дало ему понять, что вы не носитель. Другими словами, вы не говорите как носитель.\tCC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #10644468 (notenoughsun)\n",
            "Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\tНесомненно, для каждого мужчины в этом мире где-то есть подходящая женщина, которая может стать ему женой, обратное верно и для женщин. Но если учесть, что у человека может быть максимум несколько сотен знакомых, из которых лишь дюжина, а то и меньше, тех, кого он знает близко, а из этой дюжины у него один или от силы два друга, то можно легко увидеть, что с учётом миллионов живущих на Земле людей, ни один подходящий мужчина, возможно, ещё не встретил подходящую женщину.\tCC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7730831 (odexed)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "MtxSF1HljMcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+а-яА-Я\", r\" \", s)\n",
        "    return s"
      ],
      "metadata": {
        "id": "XMBj-QRDjQSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('rus.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "    \n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    for p in pairs:\n",
        "        p.pop()\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "\n",
        "    else:\n",
        "\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "    \n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "tljl5hVfjR7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s\",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "   \n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "yOLjuxPMjTXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'rus', True)\n",
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vi_9rdzjU6a",
        "outputId": "7c4b666d-5b37-415b-a5bf-9c0f7d3c104f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 451436 sentence pairs\n",
            "Trimmed to 4196 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 3874\n",
            "eng 2060\n",
            "['если честно, я на тебя полагаюсь .', 'i am relying on you to be honest .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Encoder\n",
        "-----------"
      ],
      "metadata": {
        "id": "b-0Pt5oZjZUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "7Cn_FUFKjdTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Decoder\n",
        "-----------\n"
      ],
      "metadata": {
        "id": "vt7mU-JvjeUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "qg__g07Tjf5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "wyThYIDtjimi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "metadata": {
        "id": "MDP9ut87jkCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "TJyKxGLYjl4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "Oa0AOmoejnRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "fjPg_UZAjowK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ],
      "metadata": {
        "id": "FtnGAKyfjqRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "SdsN7Hyxjr0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "trainIters(encoder1, decoder1, 75000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUFXA6AWjtKC",
        "outputId": "d90be592-cd4c-4abd-b560-af3e347be71b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3m 7s (- 43m 43s) (5000 6%) 3.0874\n",
            "6m 16s (- 40m 44s) (10000 13%) 2.4859\n",
            "9m 37s (- 38m 31s) (15000 20%) 2.0094\n",
            "12m 50s (- 35m 20s) (20000 26%) 1.5932\n",
            "16m 9s (- 32m 18s) (25000 33%) 1.2226\n",
            "19m 18s (- 28m 58s) (30000 40%) 0.9548\n",
            "22m 46s (- 26m 1s) (35000 46%) 0.7210\n",
            "26m 8s (- 22m 52s) (40000 53%) 0.5365\n",
            "29m 18s (- 19m 32s) (45000 60%) 0.3982\n",
            "32m 29s (- 16m 14s) (50000 66%) 0.2902\n",
            "36m 6s (- 13m 7s) (55000 73%) 0.2155\n",
            "39m 42s (- 9m 55s) (60000 80%) 0.1447\n",
            "43m 8s (- 6m 38s) (65000 86%) 0.1152\n",
            "46m 22s (- 3m 18s) (70000 93%) 0.0846\n",
            "49m 47s (- 0m 0s) (75000 100%) 0.0624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder1, decoder1, 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtlMUOYNjuZq",
        "outputId": "755edabb-5899-421d-871f-0a676934488c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> она хорошо плавает .\n",
            "= she swims well .\n",
            "< she is a good swimmer . <EOS>\n",
            "\n",
            "> они не будут тебе помогать .\n",
            "= they aren't going to help you .\n",
            "< they aren't going to help you . <EOS>\n",
            "\n",
            "> у него плохое настроение .\n",
            "= he is in a bad mood .\n",
            "< he is in a bad mood . <EOS>\n",
            "\n",
            "> он чрезвычаино чувствителен .\n",
            "= he is very sensitive .\n",
            "< he is very sensitive . <EOS>\n",
            "\n",
            "> ты сильныи .\n",
            "= you are strong .\n",
            "< you are strong . <EOS>\n",
            "\n",
            "> он, наверное, еще жив .\n",
            "= he is probably still alive .\n",
            "< he is still alive alive . <EOS>\n",
            "\n",
            "> мы с томом поддерживаем отношения .\n",
            "= i am on speaking terms with tom .\n",
            "< i am on speaking terms with tom . <EOS>\n",
            "\n",
            "> я пишу письмо .\n",
            "= i am writing a letter .\n",
            "< i am writing a letter . <EOS>\n",
            "\n",
            "> я твоя, а ты моя .\n",
            "= i am yours and you are mine .\n",
            "< i am yours and you are mine . <EOS>\n",
            "\n",
            "> она говорит, что одинока .\n",
            "= she says that she's lonely .\n",
            "< she says that she's lonely . <EOS>\n",
            "\n",
            "> я избранныи .\n",
            "= i am the chosen one .\n",
            "< i am the chosen one . <EOS>\n",
            "\n",
            "> она переплыла реку .\n",
            "= she swam across the river .\n",
            "< she swam across the river . <EOS>\n",
            "\n",
            "> нас нет в списке .\n",
            "= we aren't on the list .\n",
            "< we aren't on the list . <EOS>\n",
            "\n",
            "> ты не мертв .\n",
            "= you aren't dead .\n",
            "< you aren't dead . <EOS>\n",
            "\n",
            "> он квалифицированныи преподаватель англииского языка .\n",
            "= he is qualified as an english teacher .\n",
            "< he is qualified as an english teacher . <EOS>\n",
            "\n",
            "> он, что называется, человек, которыи сделал себя сам .\n",
            "= he is what is called a self-made man .\n",
            "< he is what is called a self-made man . <EOS>\n",
            "\n",
            "> я твои, а ты моя .\n",
            "= i am yours and you are mine .\n",
            "< i am yours and you are mine . <EOS>\n",
            "\n",
            "> она всего лишь ребенок .\n",
            "= she is a mere child .\n",
            "< she is only a child . <EOS>\n",
            "\n",
            "> частично за это отвечаешь ты .\n",
            "= you are in part responsible for it .\n",
            "< you are in part responsible for it . <EOS>\n",
            "\n",
            "> ему очень нравится музыка .\n",
            "= he is very fond of music .\n",
            "< he is very fond of music . <EOS>\n",
            "\n",
            "> он владелец этои земли .\n",
            "= he is the owner of this land .\n",
            "< he is the owner of this land . <EOS>\n",
            "\n",
            "> он - идеальныи муж для меня .\n",
            "= he is an ideal husband for me .\n",
            "< he is an ideal husband for me . <EOS>\n",
            "\n",
            "> мы не дураки .\n",
            "= we aren't idiots .\n",
            "< we aren't idiots . <EOS>\n",
            "\n",
            "> он будет инженером .\n",
            "= he is going to be an engineer .\n",
            "< he is going to be an engineer . <EOS>\n",
            "\n",
            "> вы систематически опаздываете на работу .\n",
            "= you are consistently late to work .\n",
            "< you are consistently late to work . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавим в encoder и decoder возможность добавлять рекурретный слой и менять rnn GRU/LSTM"
      ],
      "metadata": {
        "id": "HZ7XM7Qs7GhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_rnn = 1, rnnClass = \"GRU\"):\n",
        "        super(EncoderRNN1, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_rnn = num_rnn\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        \n",
        "        if rnnClass == \"GRU\":\n",
        "          self.rnn = nn.GRU(hidden_size, hidden_size)\n",
        "        elif rnnClass == \"LSTM\":\n",
        "          self.rnn = nn.LSTM(hidden_size, hidden_size)\n",
        "\n",
        "        if self.num_rnn == 2:\n",
        "          if rnnClass == \"GRU\":\n",
        "              self.rnn_2 = nn.GRU(hidden_size, hidden_size)\n",
        "          elif rnnClass == \"LSTM\":\n",
        "              self.rnn_2 = nn.LSTM(hidden_size, hidden_size)\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "        \n",
        "        if self.num_rnn == 2:\n",
        "          output, hidden = self.rnn_2(output, hidden)\n",
        "\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "      if isinstance(self.rnn, nn.LSTM):\n",
        "          return (torch.zeros(1, 1, self.hidden_size, device=device), torch.zeros(1, 1, self.hidden_size, device=device))\n",
        "      return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "iVj8aaQ3qVMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN1(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, num_rnn = 1, rnnClass = \"GRU\"):\n",
        "        super(DecoderRNN1, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_rnn = num_rnn\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "\n",
        "        if rnnClass == \"GRU\":\n",
        "          self.rnn = nn.GRU(hidden_size, hidden_size)\n",
        "        elif rnnClass == \"LSTM\":\n",
        "          self.rnn = nn.LSTM(hidden_size, hidden_size)\n",
        "        if self.num_rnn == 2:\n",
        "           if rnnClass == \"GRU\":\n",
        "               self.rnn_2 = nn.GRU(hidden_size, hidden_size)\n",
        "           elif rnnClass == \"LSTM\":\n",
        "               self.rnn_2 = nn.LSTM(hidden_size, hidden_size)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "\n",
        "        if self.num_rnn == 2:\n",
        "          output, hidden = self.rnn_2(output, hidden)\n",
        "\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        if isinstance(self.rnn, nn.LSTM):\n",
        "            return (torch.zeros(1, 1, self.hidden_size, device=device),torch.zeros(1, 1, self.hidden_size, device=device))\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "dn1DcRM4q8fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#GRU +1 рекуррентный слой в encoder и decoder"
      ],
      "metadata": {
        "id": "DBc21p-m7ZE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder2 = EncoderRNN1(input_lang.n_words, hidden_size, num_rnn=2).to(device)\n",
        "decoder2 = DecoderRNN1(hidden_size, output_lang.n_words, num_rnn=2).to(device)\n",
        "\n",
        "trainIters(encoder2, decoder2, 75000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN5GxxgvzccZ",
        "outputId": "7382d82d-6d24-49d4-d809-24bf1f970186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4m 58s (- 69m 32s) (5000 6%) 3.3116\n",
            "9m 26s (- 61m 23s) (10000 13%) 2.8645\n",
            "13m 59s (- 55m 56s) (15000 20%) 2.6270\n",
            "18m 33s (- 51m 1s) (20000 26%) 2.4812\n",
            "23m 15s (- 46m 31s) (25000 33%) 2.2181\n",
            "27m 51s (- 41m 46s) (30000 40%) 1.9458\n",
            "32m 30s (- 37m 8s) (35000 46%) 1.6764\n",
            "37m 6s (- 32m 28s) (40000 53%) 1.4505\n",
            "41m 42s (- 27m 48s) (45000 60%) 1.2024\n",
            "46m 24s (- 23m 12s) (50000 66%) 1.0247\n",
            "51m 4s (- 18m 34s) (55000 73%) 0.8235\n",
            "55m 44s (- 13m 56s) (60000 80%) 0.6481\n",
            "60m 31s (- 9m 18s) (65000 86%) 0.5367\n",
            "65m 41s (- 4m 41s) (70000 93%) 0.4049\n",
            "70m 30s (- 0m 0s) (75000 100%) 0.3045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder2, decoder2, 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qqC1bJTzcyq",
        "outputId": "b288ef27-0869-4b24-c727-ff4d62b63ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> она слишком маленькая, чтобы ходить в школу .\n",
            "= she is too young to go to school .\n",
            "< she is too young to go to school . <EOS>\n",
            "\n",
            "> он всегда на втором плане .\n",
            "= he is always in the background .\n",
            "< he is always complaining the others . <EOS>\n",
            "\n",
            "> я прав .\n",
            "= i am right .\n",
            "< i am right . <EOS>\n",
            "\n",
            "> у него неприятности .\n",
            "= he is in trouble .\n",
            "< he is in trouble . <EOS>\n",
            "\n",
            "> я больна .\n",
            "= i am sick .\n",
            "< i am sick . <EOS>\n",
            "\n",
            "> их здесь нет .\n",
            "= they aren't here .\n",
            "< they aren't here . <EOS>\n",
            "\n",
            "> он боится рака легких .\n",
            "= he is afraid of getting lung cancer .\n",
            "< he is afraid of getting lung cancer . <EOS>\n",
            "\n",
            "> он все еще зависит от своих родителеи .\n",
            "= he is still dependent on his parents .\n",
            "< he is still dependent on his parents . <EOS>\n",
            "\n",
            "> он очень хорошо говорит по-англииски .\n",
            "= he is a very good speaker of english .\n",
            "< he is a very good speaker of english . <EOS>\n",
            "\n",
            "> она шла и пела .\n",
            "= she sang as she walked .\n",
            "< she sang as she walked . <EOS>\n",
            "\n",
            "> вы непоследовательны .\n",
            "= you aren't consistent .\n",
            "< you aren't consistent . <EOS>\n",
            "\n",
            "> он всегда со мнои .\n",
            "= he is always with me .\n",
            "< he is always with me . <EOS>\n",
            "\n",
            "> я репортер .\n",
            "= i am a reporter .\n",
            "< i am a reporter . <EOS>\n",
            "\n",
            "> ты грубыи .\n",
            "= you are rude .\n",
            "< you are rude . <EOS>\n",
            "\n",
            "> ты женщина .\n",
            "= you are a woman .\n",
            "< you are a woman . <EOS>\n",
            "\n",
            "> ты красивая женщина .\n",
            "= you are a beautiful woman .\n",
            "< you are a beautiful woman . <EOS>\n",
            "\n",
            "> на этот раз я прав .\n",
            "= i am right for once .\n",
            "< i am right for once . <EOS>\n",
            "\n",
            "> они говорят о том о сем .\n",
            "= they are talking about this and that .\n",
            "< they are matters about the same that . <EOS>\n",
            "\n",
            "> он - очень важная особа .\n",
            "= he is a very important person .\n",
            "< he is a very important person . <EOS>\n",
            "\n",
            "> вы ведь не учитель ?\n",
            "= you aren't a teacher, are you ?\n",
            "< you aren't a student, are you ? <EOS>\n",
            "\n",
            "> они собираются эмигрировать в америку .\n",
            "= they are going to emigrate to america .\n",
            "< they are going to emigrate to america . <EOS>\n",
            "\n",
            "> она показала мне письмо, написанное на англииском языке .\n",
            "= she showed me a letter written in english .\n",
            "< she showed me a letter by in english . <EOS>\n",
            "\n",
            "> вы не сумасшедшая .\n",
            "= you aren't crazy .\n",
            "< you aren't crazy . <EOS>\n",
            "\n",
            "> я за ваше предложение .\n",
            "= i am in favor of your proposal .\n",
            "< i am in favor of your proposal . <EOS>\n",
            "\n",
            "> он близкии друг моего брата .\n",
            "= he is a close friend of my brother .\n",
            "< he is a close friend of my brother . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#LSTM"
      ],
      "metadata": {
        "id": "K5o0QEN97c33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder3 = EncoderRNN1(input_lang.n_words, hidden_size, rnnClass = \"LSTM\").to(device)\n",
        "decoder3 = DecoderRNN1(hidden_size, output_lang.n_words, rnnClass = \"LSTM\").to(device)\n",
        "\n",
        "trainIters(encoder3, decoder3, 75000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj3rBiJRzdGB",
        "outputId": "820f8db3-8ba8-447a-9581-e4028b6b989a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3m 30s (- 49m 4s) (5000 6%) 3.1849\n",
            "6m 51s (- 44m 35s) (10000 13%) 2.6784\n",
            "10m 15s (- 41m 3s) (15000 20%) 2.3025\n",
            "13m 36s (- 37m 25s) (20000 26%) 1.9213\n",
            "17m 3s (- 34m 6s) (25000 33%) 1.5495\n",
            "20m 27s (- 30m 40s) (30000 40%) 1.2868\n",
            "23m 49s (- 27m 13s) (35000 46%) 1.0512\n",
            "27m 18s (- 23m 53s) (40000 53%) 0.8202\n",
            "30m 44s (- 20m 29s) (45000 60%) 0.6584\n",
            "34m 6s (- 17m 3s) (50000 66%) 0.5053\n",
            "37m 44s (- 13m 43s) (55000 73%) 0.3757\n",
            "41m 28s (- 10m 22s) (60000 80%) 0.2802\n",
            "45m 7s (- 6m 56s) (65000 86%) 0.2055\n",
            "48m 41s (- 3m 28s) (70000 93%) 0.1454\n",
            "52m 24s (- 0m 0s) (75000 100%) 0.1128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder3, decoder3, 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXjhOaFX1M9x",
        "outputId": "42cbdb88-087a-4d9d-ab75-c91ecce9becc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> он всегда придирается к другим .\n",
            "= he is always finding fault with others .\n",
            "< he is always finding fault with others . <EOS>\n",
            "\n",
            "> мы подумываем о том, чтобы купить новую мебель .\n",
            "= we are thinking of buying some new furniture .\n",
            "< we are thinking of buying some new furniture . <EOS>\n",
            "\n",
            "> я привык жить один .\n",
            "= i am accustomed to living alone .\n",
            "< i am accustomed to living alone . <EOS>\n",
            "\n",
            "> еи не стоит идти однои .\n",
            "= she shouldn't go by herself .\n",
            "< she shouldn't go by herself . <EOS>\n",
            "\n",
            "> боюсь, он не придет .\n",
            "= i am afraid he won't come .\n",
            "< i am afraid he will come . <EOS>\n",
            "\n",
            "> он в два раза старше ее .\n",
            "= he is twice as old as she is .\n",
            "< he is twice as old as she is . <EOS>\n",
            "\n",
            "> теперь она не одна .\n",
            "= she isn't lonely now .\n",
            "< she isn't lonely now . <EOS>\n",
            "\n",
            "> вечно ты жалуешься на мужа .\n",
            "= you are always complaining about your husband .\n",
            "< you are always complaining about your husband . <EOS>\n",
            "\n",
            "> она с нетерпением ждет своего дня рождения .\n",
            "= she is looking forward to her birthday party .\n",
            "< she is looking forward to her birthday party . <EOS>\n",
            "\n",
            "> мы почти доехали .\n",
            "= we are almost there .\n",
            "< we are almost there . <EOS>\n",
            "\n",
            "> вы женщина .\n",
            "= you are a woman .\n",
            "< you are a woman . <EOS>\n",
            "\n",
            "> она привыкла не спать всю ночь .\n",
            "= she is used to staying up all night .\n",
            "< she is used to staying up all night . <EOS>\n",
            "\n",
            "> он не такои умныи, как мои брат .\n",
            "= he is not as clever as my brother .\n",
            "< he is not as clever as my brother . <EOS>\n",
            "\n",
            "> он занят написанием отчетов .\n",
            "= he is busy typing the reports .\n",
            "< he is busy typing the reports . <EOS>\n",
            "\n",
            "> он нам не враг .\n",
            "= he isn't our enemy .\n",
            "< he isn't our enemy . <EOS>\n",
            "\n",
            "> там нельзя парковаться .\n",
            "= you aren't allowed to park there .\n",
            "< you aren't allowed to park there . <EOS>\n",
            "\n",
            "> она сеичас пьет кофе .\n",
            "= she is having coffee now .\n",
            "< she is having coffee now . <EOS>\n",
            "\n",
            "> я огромныи поклонник американскои культуры .\n",
            "= i am a great admirer of american culture .\n",
            "< i am a great a great a american . <EOS>\n",
            "\n",
            "> ты веселыи .\n",
            "= you are hilarious .\n",
            "< you are hilarious . <EOS>\n",
            "\n",
            "> я объясняю правила .\n",
            "= i am explaining the rules .\n",
            "< i am explaining the rules . <EOS>\n",
            "\n",
            "> он учится, чтобы стать священником .\n",
            "= he is studying to be a minister .\n",
            "< he is studying to be a minister . <EOS>\n",
            "\n",
            "> не я один так думаю .\n",
            "= i am not alone in thinking so .\n",
            "< i am not alone in thinking so . <EOS>\n",
            "\n",
            "> у меня работы невпроворот .\n",
            "= i am swamped with work .\n",
            "< i am swamped with work . <EOS>\n",
            "\n",
            "> он вдвое старше ее .\n",
            "= he is twice as old as she is .\n",
            "< he is twice as old as she is . <EOS>\n",
            "\n",
            "> он, говорят, хорошии доктор .\n",
            "= he is said to be a good doctor .\n",
            "< he is said to be a good doctor . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#LSTM +1 рекуррентный слой"
      ],
      "metadata": {
        "id": "sgWWxppJ7j91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder4 = EncoderRNN1(input_lang.n_words, hidden_size, num_rnn=2, rnnClass = \"LSTM\").to(device)\n",
        "decoder4 = DecoderRNN1(hidden_size, output_lang.n_words, num_rnn=2, rnnClass = \"LSTM\").to(device)\n",
        "\n",
        "trainIters(encoder4, decoder4, 75000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVIX6yE61NTQ",
        "outputId": "9019a4e3-d1fd-42e2-8202-675dcf3a9a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4m 54s (- 68m 49s) (5000 6%) 3.3758\n",
            "10m 0s (- 65m 1s) (10000 13%) 3.1475\n",
            "15m 1s (- 60m 5s) (15000 20%) 3.0216\n",
            "20m 1s (- 55m 3s) (20000 26%) 2.7356\n",
            "25m 17s (- 50m 34s) (25000 33%) 2.6157\n",
            "30m 29s (- 45m 44s) (30000 40%) 2.4327\n",
            "35m 38s (- 40m 43s) (35000 46%) 2.3440\n",
            "40m 53s (- 35m 46s) (40000 53%) 2.2050\n",
            "46m 10s (- 30m 46s) (45000 60%) 2.0994\n",
            "51m 28s (- 25m 44s) (50000 66%) 1.9524\n",
            "56m 43s (- 20m 37s) (55000 73%) 1.8216\n",
            "61m 48s (- 15m 27s) (60000 80%) 1.6574\n",
            "67m 0s (- 10m 18s) (65000 86%) 1.5555\n",
            "72m 8s (- 5m 9s) (70000 93%) 1.3570\n",
            "77m 46s (- 0m 0s) (75000 100%) 1.2079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder4, decoder4, 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYnobDkw1fvZ",
        "outputId": "c1f4f769-4aab-457e-d9b7-01dce7ced916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> ты невыносима .\n",
            "= you are impossible .\n",
            "< you are special . <EOS>\n",
            "\n",
            "> у него хорошие способности к гимнастике .\n",
            "= he is good at gymnastics .\n",
            "< he is good at cooking . <EOS>\n",
            "\n",
            "> он прирожденныи художник .\n",
            "= he is a born artist .\n",
            "< he is a simple man . <EOS>\n",
            "\n",
            "> я думаю поехать за границу .\n",
            "= i am thinking of going abroad .\n",
            "< i am thinking of going abroad . <EOS>\n",
            "\n",
            "> им совсем неинтересно .\n",
            "= they are not at all interested .\n",
            "< they are not at all interested . <EOS>\n",
            "\n",
            "> он водитель автобуса .\n",
            "= he is a bus driver .\n",
            "< he is a . . <EOS>\n",
            "\n",
            "> они разговаривают на кухне .\n",
            "= they are talking in the kitchen .\n",
            "< they are in the kitchen . <EOS>\n",
            "\n",
            "> он всегда дарит подарки своеи жене .\n",
            "= he is always giving presents to his wife .\n",
            "< he is always complaining about his his wife . <EOS>\n",
            "\n",
            "> вы ослеплены любовью .\n",
            "= you are blinded by love .\n",
            "< you are taller than me . <EOS>\n",
            "\n",
            "> она к нему не добра .\n",
            "= she isn't kind to him .\n",
            "< she isn't answering her . <EOS>\n",
            "\n",
            "> я боюсь, что вы потеряетесь .\n",
            "= i am afraid that you will get lost .\n",
            "< i am afraid that you will get . <EOS>\n",
            "\n",
            "> она говорила через переводчика .\n",
            "= she spoke through an interpreter .\n",
            "< she is at with her . <EOS>\n",
            "\n",
            "> они готовятся к поездке .\n",
            "= they are making preparations for the trip .\n",
            "< they are bound together for tea . <EOS>\n",
            "\n",
            "> я знаком с этим обычаем .\n",
            "= i am acquainted with the custom .\n",
            "< i am looking with friends . <EOS>\n",
            "\n",
            "> ты абсолютно прав !\n",
            "= you are absolutely right .\n",
            "< you are drunk ! <EOS>\n",
            "\n",
            "> ты несешь ответственность за результат .\n",
            "= you are responsible for the result .\n",
            "< you are in part responsible . <EOS>\n",
            "\n",
            "> его здесь нет, не так ли ?\n",
            "= he isn't here, is he ?\n",
            "< he isn't here, is he ? <EOS>\n",
            "\n",
            "> сеичас я в старом замке .\n",
            "= i am now in an old castle .\n",
            "< i am going to play tennis . <EOS>\n",
            "\n",
            "> он - помощник археолога .\n",
            "= he is an archeologist's assistant .\n",
            "< he is a big man . <EOS>\n",
            "\n",
            "> еи не привыкать к публичным выступлениям .\n",
            "= she is used to speaking in public .\n",
            "< she is in of all all all . <EOS>\n",
            "\n",
            "> он нам не враг .\n",
            "= he isn't our enemy .\n",
            "< he isn't perfect . <EOS>\n",
            "\n",
            "> он преуспевает .\n",
            "= he is in the money .\n",
            "< he is in the . . <EOS>\n",
            "\n",
            "> ты большои .\n",
            "= you are big .\n",
            "< you are rich . <EOS>\n",
            "\n",
            "> она бегло говорит по-англииски и французски .\n",
            "= she is fluent in english and french .\n",
            "< she is very popular among the boys . <EOS>\n",
            "\n",
            "> она стремится жить в австралии .\n",
            "= she is eager to live in australia .\n",
            "< she is in in her the . . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итого обучены сети:\n",
        "* GRU 1 рекуррентный слой   loss = 0.0624    3 неточности на 25 предложений\n",
        "* GRU 2 рекуррентных слоя   loss = 0.3045    4 / 25 предложений\n",
        "* LSTM 1 рекуррентный слой  loss = 0.1128    2 / 25 предложений\n",
        "* LSTM 2 рекуррентных слоя  loss = 1.2079    21 / 25 предложений\n",
        "Замена GRU на LSTM на время обучения практически не повлияло, а вот добавление рекурретного слоя увеличело время обучения чуть меньше, чем в 2 раза.\n",
        "\n",
        "Изучение примеров генерации перевода говорит о том, что лучшее качество у LSTM и GRU c 1 рекуррентным слоем.\n",
        "GRU с 2 рекуррентными слоями тоже неплох. \n",
        "\n",
        "А вот LSTM с 2 рекуррентными слоями выглядит местами довольно комично :-)\n",
        "\n",
        "> ты невыносима .\n",
        "= you are impossible .\n",
        "< you are special . <EOS>\n",
        "\n",
        "> ты абсолютно прав !\n",
        "= you are absolutely right .\n",
        "< you are drunk ! <EOS>"
      ],
      "metadata": {
        "id": "dRO25DPi83TP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_IpbmX94gvn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}